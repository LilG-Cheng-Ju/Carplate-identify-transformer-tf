{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "import os \n",
    "import tensorflow_addons as tfa\n",
    "from skimage import io,transform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf16620",
   "metadata": {},
   "source": [
    "# Read training data in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96acab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'D:\\Training_data_sets\\Car-plate\\Origin'\n",
    "Folder = os.listdir(PATH)\n",
    "\n",
    "for file in Folder:\n",
    "\n",
    "    img = io.imread(PATH+'/'+ file)\n",
    "    (img[:,:,0])[(img[:,:,3]) > 1] = 255\n",
    "    (img[:,:,1])[(img[:,:,3]) > 1] = 255\n",
    "    (img[:,:,2])[(img[:,:,3]) > 1] = 255\n",
    "\n",
    "    img = transform.resize(img,(40,150))\n",
    "    print(img)\n",
    "    output = img[0:-8,3:-3,:]\n",
    "\n",
    "    io.imsave(r'D:\\Training_data_sets\\Car-plate\\Reshape'+'/'+file,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ef814",
   "metadata": {},
   "source": [
    "# Embed token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'D:\\Training_data_sets\\Car-plate\\Reshape'\n",
    "Folder = os.listdir(PATH)\n",
    "\n",
    "Train_input = []\n",
    "Target = []\n",
    "for file in Folder:\n",
    "    \n",
    "    img = io.imread(PATH+'/'+ file)\n",
    "    \n",
    "    \n",
    "    word = ['BOS'] + list(file[:-4]) + ['EOS']\n",
    "    Target.append(word)\n",
    "    Train_input.append(img[:,:,0:3])\n",
    "    \n",
    "Train_input = np.asarray(Train_input)\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(Target)\n",
    "\n",
    "Train_target = tokenizer.texts_to_sequences(Target)\n",
    "Train_target = keras.preprocessing.sequence.pad_sequences(Train_target,maxlen=10,padding='post')\n",
    "Train_target = np.asarray(Train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in Train_target:\n",
    "    print([tokenizer.index_word[idx].upper() for idx in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806b092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.max(Train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaa9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "io.imshow(Train_input[15])\n",
    "print([tokenizer.index_word[idx].upper() for idx in Train_target[15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a9146",
   "metadata": {},
   "source": [
    "# Img 2 Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgPatches(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,patch_size,):\n",
    "        super(ImgPatches,self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(d_model,patch_size,patch_size,padding = 'valid')\n",
    "        self.patch_size = patch_size\n",
    "        self.d_model = d_model\n",
    "    def call(self,x):\n",
    "        batch_size = x.get_shape()[0]\n",
    "        x = self.conv1(x)\n",
    "        def Reshape(x):\n",
    "            x = tf.reshape(x,(-1,tf.multiply(x.get_shape()[1],x.get_shape()[2]),x.get_shape()[3]))\n",
    "            return x\n",
    "        x = tf.keras.layers.Lambda(Reshape)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImgPatches(d_model = 32,patch_size=16)\n",
    "y = img((Train_input/255).astype('float32'))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  \n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174adfd2",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a715e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_heads,d_model,dff,dropout_rate = 0.1):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        #self.Add = Add()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,key_dim = d_model)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self,inp,training = True):\n",
    "        x = self.norm1(inp)\n",
    "        x = self.mha(x,x)\n",
    "        x = self.dropout1(x,training = training)\n",
    "        x = x + inp\n",
    "\n",
    "        y = self.norm2(x)\n",
    "        y = self.ffn(y)\n",
    "        y = x+y\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = EncoderBlock(2,32,64)\n",
    "y = E(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fe514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_heads,d_model,dff,num_layers,dropout_rate = 0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.encoder_layers = [EncoderBlock(num_heads,d_model,dff,dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
    "        self.num_layers = num_layers\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self,x,training = True):\n",
    "        emb = positional_encoding(x.get_shape()[1],x.get_shape()[2])\n",
    "        x = tf.add(x,emb)\n",
    "        for layer in range(self.num_layers):\n",
    "            x = self.encoder_layers[layer](x,training=training)\n",
    "        x = self.norm1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7445889",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Encoder(2,32,64,2)\n",
    "y = E(y)\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4e426",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c683c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_forward_mask(size):\n",
    "    mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_forward_mask = create_look_forward_mask(Train_target.shape[1])\n",
    "look_forward_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99516f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "       \n",
    "        self.mha1 = tfa.layers.MultiHeadAttention(d_model, num_heads,return_attn_coef = True)\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output,look_forward_mask, training):\n",
    "       \n",
    "        attn1,_ = self.mha1([x, x],mask = look_forward_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "   \n",
    "        attn2 = self.mha2(out1, enc_output)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57606cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_target = Train_target.astype(\"float32\")\n",
    "Train_target = tf.convert_to_tensor(Train_target)\n",
    "\n",
    "# Train_target = Train_target[tf.newaxis,...]\n",
    "Train_target.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = DecoderBlock(2,32,64)\n",
    "y = E(y,Train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c854b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 為中文（目標語言）建立詞嵌入層\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderBlock(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
    "    def call(self, x, enc_output,look_forward_mask, training = True):\n",
    "\n",
    "        tar_seq_len = tf.shape(x)[1]  \n",
    "\n",
    "        # 這邊跟 Encoder 做的事情完全一樣\n",
    "        x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
    "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :tar_seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "\n",
    "        for i, dec_layer in enumerate(self.dec_layers):\n",
    "            x,_ = dec_layer(x, enc_output,look_forward_mask, training)\n",
    "\n",
    "\n",
    "            # x.shape == (batch_size, tar_seq_len, d_model)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "D = Decoder(1,32,2,64,36)\n",
    "X  = D(Train_target,y,look_forward_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05440e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
    "    def __init__(self,patch_size ,num_layers, d_model, num_heads, dff, target_vocab_size, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.ImagePatches = ImgPatches(d_model,patch_size)\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, rate)\n",
    "        # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
    "    # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
    "    def call(self, inp, tar,look_forward_mask, training=True):\n",
    "        \n",
    "        inp = self.ImagePatches(inp)\n",
    "        \n",
    "        enc_output = self.encoder(inp, training)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output = self.decoder(tar, enc_output,look_forward_mask, training)\n",
    "\n",
    "        # 將 Decoder 輸出通過最後一個 linear layer\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713acd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Transformer(16,2,32,2,64,36)\n",
    "A = T((Train_input/255).astype('float32'),Train_target,look_forward_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5017845",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "d_model = 32\n",
    "dff = 64\n",
    "num_heads = 2\n",
    "patch_size = 16\n",
    "\n",
    "num_of_token = 36\n",
    "dropout_rate = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    # 論文預設 `warmup_steps` = 4000\n",
    "    def __init__(self, d_model, warmup_steps=4):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
    "# Adam opt. 的參數都跟論文相同\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(0.003, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9,decay = 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cartransformer = Transformer(patch_size,num_layers, d_model, num_heads, dff,num_of_token, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = (r'C:\\Users\\User\\GGjupyter\\checkpoint\\Car_transformer_1layer')\n",
    "log_dir = (r'C:\\Users\\User\\GGjupyter\\checkpoint\\Car_transformer_1layer')\n",
    "\n",
    "# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
    "# 一般來說你會想存下模型以及 optimizer 的狀態\n",
    "ckpt = tf.train.Checkpoint(cartransformer=cartransformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
    "# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "\n",
    "    # 用來確認之前訓練多少 epochs 了\n",
    "    last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
    "    print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print(\"沒找到 checkpoint，從頭訓練。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e666e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  \n",
    "def train_step(inp, tar):\n",
    "    \n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    look_forward_mask = create_look_forward_mask(tar_inp.shape[1])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "       \n",
    "        predictions = cartransformer(inp, tar_inp,look_forward_mask, True)\n",
    "        \n",
    "        loss = loss_object(tar_real, predictions)\n",
    "   \n",
    "    gradients = tape.gradient(loss, cartransformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, cartransformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0000cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 用來寫資訊到 TensorBoard，非必要但十分推薦\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  \n",
    "    # 重置紀錄 TensorBoard 的 metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "  # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 \n",
    "    i=1\n",
    "    for inp, tar in zip((Train_input).astype('float32'),Train_target):\n",
    "#         print(\"epoch\", epoch+1,\"step\",i)\n",
    "        inp = tf.convert_to_tensor(inp)\n",
    "        inp = inp[tf.newaxis, ...]\n",
    "        \n",
    "        tar = tf.convert_to_tensor(tar)\n",
    "        tar = tar[tf.newaxis, ...]\n",
    "        \n",
    "\n",
    "    # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss\n",
    "        train_step(inp, tar)  \n",
    "        i+=1\n",
    "  # 每個 epoch 完成就存一次檔    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "    \n",
    "  # 將 loss 以及 accuracy 寫到 TensorBoard 上\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
    "        tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
    "  \n",
    "        print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "cartransformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24237c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  \n",
    "    # 準備英文句子前後會加上的 <start>, <end>\n",
    "    start_token = 1\n",
    "    end_token = 3\n",
    "\n",
    "    inp_sentence = inp_sentence[tf.newaxis, ...]\n",
    "\n",
    "    # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
    "    # 是一個只包含一個中文 <start> token 的序列\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
    "    # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
    "    for i in range(10):\n",
    "    # 每多一個生成的字就得產生新的遮罩\n",
    "        look_forward_mask = create_look_forward_mask(output.shape[1])\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions = cartransformer(inp_sentence,output,look_forward_mask,False )\n",
    "        # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
    "        predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
    "        if tf.equal(predicted_id, end_token):\n",
    "            Carplate = np.asarray(output)\n",
    "#             print('A')\n",
    "            print([tokenizer.index_word[idx].upper() for idx in Carplate[0]])\n",
    "            return tf.squeeze(output, axis=0)\n",
    "            \n",
    "        \n",
    "        Carplate = np.asarray(output)\n",
    "#         print('B')\n",
    "        print([tokenizer.index_word[idx].upper() for idx in Carplate[0]])\n",
    "        #將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
    "        # 下個中文字的時候關注到最新的 `predicted_id`\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18492ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([tokenizer.index_word[idx].upper() for idx in Carplate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432804c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([tokenizer.index_word[idx].upper() for idx in Train_target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b991285",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Train_input[22]\n",
    "# Train_input[22]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp, tar in zip((Train_input/255).astype('float32'),Train_target):\n",
    "    try:\n",
    "        inp = tf.convert_to_tensor(inp)\n",
    "        inp = inp[tf.newaxis, ...]\n",
    "        \n",
    "        tar = tf.convert_to_tensor(tar)\n",
    "        tar = tar[tf.newaxis, ...]\n",
    "        tar_inp = tar[:, :-1]\n",
    "        tar_real = tar[:, 1:]\n",
    "        \n",
    "        inp = np.asarray(inp[0])\n",
    "        tar = np.asarray(tar[0])\n",
    "        tar_inp = np.asarray(tar_inp[0])\n",
    "        tar_real = np.asarray(tar_real[0])\n",
    "        \n",
    "        \n",
    "        print([tokenizer.index_word[idx].upper() for idx in tar])\n",
    "        print([tokenizer.index_word[idx].upper() for idx in tar_inp])\n",
    "        print([tokenizer.index_word[idx].upper() for idx in tar_real])\n",
    "        io.imshow(inp*255)\n",
    "        io.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5246bf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
